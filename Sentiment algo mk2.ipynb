{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, SpatialDropout1D\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "======================================\n",
      "Time to manage data: 5.0533013343811035\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "#vars\n",
    "vocab_size = 5000\n",
    "embedding_size = 128\n",
    "\n",
    "LSTM_units = 128\n",
    "Dense_units = 1\n",
    "\n",
    "start_data = time.time()\n",
    "\n",
    "#data\n",
    "data = pd.read_csv('train.csv', encoding='latin-1')\n",
    "\n",
    "#tokenization\n",
    "t = Tokenizer(num_words = vocab_size, split = ' ')\n",
    "t.fit_on_texts(data['SentimentText'])\n",
    "X = t.texts_to_sequences(data['SentimentText'].values)\n",
    "\n",
    "#make everything the same length\n",
    "X = pad_sequences(X)\n",
    "\n",
    "max_words = X.shape[1]\n",
    "\n",
    "#train/test split\n",
    "X_train = X[:int(X.shape[0]*0.8)]\n",
    "X_test = X[int(X.shape[0]*.8):]\n",
    "\n",
    "Y_train = data[:int(data.shape[0]*0.8)].Sentiment\n",
    "Y_test = data[int(data.shape[0]*.8):].Sentiment\n",
    "\n",
    "#print time that it took\n",
    "end_data = time.time()\n",
    "print('=======================================')\n",
    "print('Time to manage data: ' + str(end_data - start_data))\n",
    "print('=======================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length = max_words))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(LSTM_units, dropout = .2, recurrent_dropout = .2))\n",
    "model.add(Dense(Dense_units, activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, \n",
    "                                          write_graph=True, write_images=True)\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size = 32, epochs = 1, \n",
    "                    validation_split = 0.20, shuffle = True, verbose = 1, \n",
    "                    `callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
